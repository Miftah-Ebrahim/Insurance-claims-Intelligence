{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4: Statistical Modeling and Evaluation\n",
    "\n",
    "In this notebook, we build and evaluate predictive models for a dynamic, risk-based pricing system.\n",
    "\n",
    "## Objectives\n",
    "1.  **Claim Severity Prediction (Regression)**: Predict `TotalClaims` for policies with a claim.\n",
    "2.  **Claim Probability Prediction (Classification)**: Predict the likelihood (`IsClaim`) of a claim occurring.\n",
    "3.  **Interpretability**: Use SHAP values to explain the key drivers of risk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "# Ensure src modules are importable\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from src.data.loader import load_data\n",
    "from src.features.build_features import DataBuilder\n",
    "from src.models.train_model import ModelTrainer\n",
    "\n",
    "# Output Setup\n",
    "sns.set_style(\"whitegrid\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Preparation\n",
    "We load the raw data and pass it through our `DataBuilder` pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/raw/MachineLearningRating.txt'\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    DATA_PATH = 'data/raw/MachineLearningRating.txt'\n",
    "\n",
    "df_raw = load_data(DATA_PATH)\n",
    "print(f\"Raw Data Shape: {df_raw.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and Run Preprocessing Pipeline\n",
    "builder = DataBuilder(df_raw)\n",
    "df_processed = builder.preprocess()\n",
    "\n",
    "print(f\"Processed Data Shape: {df_processed.shape}\")\n",
    "df_processed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model 1: Claim Severity (Regression)\n",
    "**Goal**: Predict `TotalClaims` amount using only positive claim cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get specific dataset for Severity\n",
    "X_severity, y_severity = builder.get_severity_data()\n",
    "print(f\"Severity Dataset: {X_severity.shape}\")\n",
    "\n",
    "# Split\n",
    "X_train_sev, X_test_sev, y_train_sev, y_test_sev = builder.split_data(X_severity, y_severity)\n",
    "\n",
    "# Initialize Trainer\n",
    "trainer = ModelTrainer()\n",
    "\n",
    "# Train Regression Models\n",
    "trainer.train_severity_models(X_train_sev, X_test_sev, y_train_sev, y_test_sev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model 2: Claim Probability (Classification)\n",
    "**Goal**: Predict binary probability of a claim occurring (`IsClaim=1`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get specific dataset for Probability\n",
    "X_prob, y_prob = builder.get_probability_data()\n",
    "print(f\"Probability Dataset: {X_prob.shape}\")\n",
    "\n",
    "# Split\n",
    "X_train_prob, X_test_prob, y_train_prob, y_test_prob = builder.split_data(X_prob, y_prob)\n",
    "\n",
    "# Train Classification Models\n",
    "trainer.train_probability_models(X_train_prob, X_test_prob, y_train_prob, y_test_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Evaluation & Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = trainer.get_results()\n",
    "display(results)\n",
    "\n",
    "# Visualize RMSE for Regression\n",
    "plt.figure(figsize=(10, 5))\n",
    "reg_res = results[results.index.str.contains(\"Severity\")]\n",
    "sns.barplot(x=reg_res.index, y=reg_res['RMSE'], palette='viridis')\n",
    "plt.title(\"Claim Severity Model Comparison (RMSE - Lower is Better)\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Interpretability (SHAP)\n",
    "We analyse the best performing model (typically XGBoost) to understand feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret_model(model, X_train, model_name):\n",
    "    print(f\"Interpreting {model_name} with SHAP...\")\n",
    "    try:\n",
    "        # Use TreeExplainer for Tree models\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_train)\n",
    "        \n",
    "        plt.title(f\"SHAP Summary: {model_name}\")\n",
    "        shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"Detailed Feature Impact:\")\n",
    "        shap.summary_plot(shap_values, X_train)\n",
    "    except Exception as e:\n",
    "        print(f\"SHAP failed: {e}\")\n",
    "        # Fallback to feature importance\n",
    "        if hasattr(model, 'feature_importances_'):\n",
    "            feat_importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "            feat_importances.nlargest(10).plot(kind='barh')\n",
    "            plt.title(\"Feature Importance (Fallback)\")\n",
    "            plt.show()\n",
    "\n",
    "# Interpret best Probability Model (e.g., XGBoost)\n",
    "if 'Probability_XGB' in trainer.models:\n",
    "    interpret_model(trainer.models['Probability_XGB'], X_train_prob, \"XGBoost Classification\")\n",
    "elif 'Probability_RF' in trainer.models:\n",
    "    interpret_model(trainer.models['Probability_RF'], X_train_prob, \"RandomForest Classification\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "The analysis provides a dual-framework for pricing:\n",
    "1.  **Risk Probability**: Identified drivers of *accident frequency*.\n",
    "2.  **Risk Severity**: Identified drivers of *cost* when accidents occur.\n",
    "\n",
    "By combining these, we can formulate an optimal premium:\n",
    "> **Premium** = (P(Claim) * E[Claim Cost]) + Margin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}